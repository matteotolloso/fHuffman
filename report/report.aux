\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand*\HyPL@Entry[1]{}
\citation{*}
\HyPL@Entry{0<</S/D>>}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{2}{section.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {2}Overview}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Counting the number of occurences}{2}{subsection.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Building the binary tree}{3}{subsection.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Encoding the file}{3}{subsection.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Technical details}{3}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Implementation}{3}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Overheads}{4}{subsection.3.2}\protected@file@percent }
\newlabel{sec:tests}{{4}{5}{Tests}{section.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Tests }{5}{section.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Sequential times for 8GB file of random characters. Averaged over 10 runs.\relax }}{5}{table.caption.7}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{tab:sequential_times}{{1}{5}{Sequential times for 8GB file of random characters. Averaged over 10 runs.\relax }{table.caption.7}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Parallel times with FastFlow implementation for 8GB file of random characters. 32 physical core machine. Averaged over 10 runs.\relax }}{6}{table.caption.8}\protected@file@percent }
\newlabel{tab:ff_times}{{2}{6}{Parallel times with FastFlow implementation for 8GB file of random characters. 32 physical core machine. Averaged over 10 runs.\relax }{table.caption.8}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Parallel times with native threads implementation for 8GB file of random characters. 32 physical core machine. Averaged over 10 runs.\relax }}{6}{table.caption.9}\protected@file@percent }
\newlabel{tab:thr_times}{{3}{6}{Parallel times with native threads implementation for 8GB file of random characters. 32 physical core machine. Averaged over 10 runs.\relax }{table.caption.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Time for encoding of a 8GB file of random characters, in seconds. Averaged over 10 runs.\relax }}{7}{figure.caption.10}\protected@file@percent }
\newlabel{fig:time_to_complete}{{1}{7}{Time for encoding of a 8GB file of random characters, in seconds. Averaged over 10 runs.\relax }{figure.caption.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Efficiency in the encoding of a 8GB file of random characters. Averaged over 10 runs.\relax }}{8}{figure.caption.11}\protected@file@percent }
\newlabel{fig:efficiency}{{2}{8}{Efficiency in the encoding of a 8GB file of random characters. Averaged over 10 runs.\relax }{figure.caption.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Time to encode a 8GB file of random characters. Standart malloc library vs jemalloc. 32 physical core machine. Averaged over 10 runs. The term ``speedup'' here has a different meaning than the usual one: it is the ratio between the time with the standart library and the time with jemalloc.\relax }}{8}{table.caption.12}\protected@file@percent }
\newlabel{tab:jemalloc}{{4}{8}{Time to encode a 8GB file of random characters. Standart malloc library vs jemalloc. 32 physical core machine. Averaged over 10 runs. The term ``speedup'' here has a different meaning than the usual one: it is the ratio between the time with the standart library and the time with jemalloc.\relax }{table.caption.12}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Parallel times with FastFlow implementation for 8GB file of random characters. 16 physical core machine. Averaged over 10 runs.\relax }}{9}{table.caption.13}\protected@file@percent }
\newlabel{tab:ff_times16}{{5}{9}{Parallel times with FastFlow implementation for 8GB file of random characters. 16 physical core machine. Averaged over 10 runs.\relax }{table.caption.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Time for encoding different sized files of random characters, in $ \mu s$, with 32 physical cores. Averaged over 10 runs.\relax }}{9}{figure.caption.14}\protected@file@percent }
\newlabel{fig:small_files}{{3}{9}{Time for encoding different sized files of random characters, in $ \mu s$, with 32 physical cores. Averaged over 10 runs.\relax }{figure.caption.14}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Conclusions}{9}{section.5}\protected@file@percent }
\gdef \@abspage@last{10}
